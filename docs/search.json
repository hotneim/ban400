[
  {
    "objectID": "01-intro-to-r.html",
    "href": "01-intro-to-r.html",
    "title": "BAN400 - R Programming for Data Science",
    "section": "",
    "text": "Welcome to the first taste of BAN400. We will start by downloading and installing the tools that we need to start coding, and then we will explore some of the most basic aspects of the R programming language. After most of the videos we have included a small problem that we encourage you to try before you move on to the next topic.\nBefore we start, you need to install two items on your computer. Please do the installations in the following order:\n\nThe R Programming Language: Navigate to cran.uib.no and download the version of R that corresponds to your operating system. Run the installation as you would for any other program that you install on your system.\nRStudio: Navigate to posit.co/download/rstudio-desktop/, and download the version of “RStudio Desktop” that corresponds to your operating system. Run the installation as you would for any other program that you install on your computer.\n\nBoth R and RStudio are free to download and free to use.\n\n\n\n\nIn this video we open up RStudio for the first time and take a small tour of the user interface.\n\n\n\n\n\nWe move on to write our first R commands. It is critical that you already now start to feel the programming, and you do that best by typing in the code lines just as in the video above (no copy/paste!), making sure that you get the same results.\n\n# We can use R as a calculator:\n2+2\n\n# Pretty simple! We must use paratheses if we have more complicated expressions:\n(2+8)/2\n2+8/2\n\n# Variables are important in R. We can save just about anything inside the\n# computer memory by giving them names:\na <- 5\na\na*4 \n\nb <- 3\n\n# R performs all operations on the right hand side before assigning the value to c:\nc <- a+b\nc\n\n# No errors, warnings or questions when overwriting!\nc <- 4\n\nc <- c + 2\nc\n\n# Let's make an error!\nd\n\n# We can name things more or less what we want. Not a non-trivial problem in\n# large projects!\nwhatever_we_want <- \"hello world\"\nwhatever_we_want\n\nExercise:\nPick your favorite three integers and store them in three different variables. Calculate yor magic number, which is the sum of these three integers. Store your magic number in a new variable. Give your new variable a name that clearly identifies what it is.\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\nnumber1 <- 1\nnumber2 <- 87\nnumber3 <- 101\n\nmagic_number <- number1 + number2 + number3\n\n\n\n\n\n\n\n\n\nVectors are very important in R. We remember perhaps from our math classes that vectors may represent points in space; in R it is a way to store more than one number (or string, or some other data type) under a single variable name. When doing statistics, this may for example be a set of observations.\nIn this video we first create a vector of numbers using the c()-function, and then we look at various ways to extract/pick out the elements: to subset. Python coders will notice two important distinctions from what they are used to:\n\nIn R we start counting on 1, and not 0!\nWhen trying to subset using an index that out of the range of the vector, we do not get an error message, we just get back the empty value NA.\n\nFurthermore, we use the Up-arrow to get back the last command that we have executed in the console. You can even tap the up-arrow again in order go further back in your command history (and of course use the down-arrow to navigate the other way).\n\n# We can make a vector in the following way:\nvector1 <- c(3, 5, 7.8, 10, 2, 0.16, -3)\n\n# Print out\nvector1\n\n# Subsetting (The first item has index 1!)\nvector1[1]        # Square brackets to subset\nvector1[10]       # Out-of-range error\nvector1[2:5]      # Subset a sequence\nvector1[c(1,3)]   # Subset using another vector!\n\n# The letter \"c\" stands for \"combine\". R makes it very easy to work with\n# vectors:\nvector1 - 1\nvector1*3\n\n# We can use *functions* to calculate various things:\nlength(vector1)\nmean(vector1)\nsum(vector1)\nsd(vector1)\n\n# We can make a vector of strings as well:\nvector2 <- c(\"hello\", \"world\")\n\n# A vector can only contain one data type!\n\n# Perhaps we need the standard deviation later?\nsd_vector1 <- sd(vector1)\nsd_vector1\n\nExercise:\nCalculate the maximum and minimum values of vector1, as well as the median. (Hint, and this will be the most important lesson you will learn in this course: If you do not know the name of the function, Google it!)\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n# Relevant Google searches: \"minimum value r\", \"maximum r\", \"median r\"\n\nmin(vector1)\nmax(vector1)\nmedian(vector1)\n\n\n\n\n\n\n\n\n\nIn this video we install our first package in R. There are two major takeaways from this:\n\nWe install the package on our computer using the install.packages()-function. We only have to do this once per computer.\nIf we are going to use some of the functions in a package we need to load it using the library()-command. You have to do that every time you restart R (and we will later see that we will typically load all the packages we need in the beginning of the scripts that we write).\n\n\n# In order to install the package readxl, we run the following command. \n# We run this command only once.\ninstall.packages(\"readxl\")\n\n# When we are going to use it, we load it using the \"library()\"-function, \n# and we need to repreat this every time we restart R.\nlibrary(readxl)\n\nExercise: Install the following packages. We will make use of them (and several others) later in the course: ggplot2, dplyr, tidyr and lubridate.\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\ninstall.packages(\"ggplot2\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"tidyr\")\ninstall.packages(\"lubridate\")\n\n\n\n\n\n\n\n\n\nWe introduce the concept of a working directory, which is the folder where R looks for files that we are going to read into the memory, and where R puts the files that we create, for instance image files of plots.\nThere are two central functions:\n\ngetwd() prints out the current working directory.\nsetwd(\"C:/path/to/folder\") sets the working directory to the specified folder. We will as a general rule not use setwd() in our scripts (the reason for that will become clear later), but rather use RStudio’s menu system for changing the working directory (we will in practice not need to do that as a general rule as well, which will also become clear in a short while).\n\nWe may however have to deal with file paths in our code, and make the following technical notes:\n\nOn UNIX systems (such as Mac or Linux) the file paths look differently, they do not start with a drive letter such as C:\\.\nOn Windows, we always use the backslash / to separate between the folders in R code, and not the usual forward slash \\. This may be counter-intuitive to some, but in programming the forward slash usually has special meaning (the escape character) and must not be used for anything else. On UNIX systems we also use the backslash, but that is the system standard for writing file paths, so it does not require any special attention to users of those operating systems.\n\nExercise: Make sure that you have completed the following tasks before proceding to the next lesson:\n\nYou have created a dedicated folder on your computer where you will collected all material that we will use today.\nYou have downloaded the file testdata.xls and put in in your newly created folder.\nYou have changed your working directory to this folder.\nYou have positively confirmed that your working directory now is correctly set.\n\n\n\n\n\n\nWe read our first small data file into the memory of R and apply some simple operations to it. We will spend much more time working with data in R in later lessons.\n\n# The data is in the .xls-format, so we need the readxl-package in order to load \n# it into R.\nlibrary(readxl)\n\n# Inside this package, there is a function called read_excel:\nread_excel(\"testdata.xls\")\n\n# That's fine, but in order to use this data, we need to save it in a variable\ntestdata <- read_excel(\"testdata.xls\")\n\n# Print out the (top of the) data set.\ntestdata\n\n# Now we see the data in the environment. We can look at it by typing the name that we\n# gave it. We can also pick out individual columns using the $-sign:\ntestdata$X1\n\n# Calaculate the mean for X1 and X2:\nmean(testdata$X1)\nmean(testdata$X2)\n\n# How many rows/observations do we have?\nnrow(testdata)\n\nExercise:\n\nHow many columns does our data set have?\nCan you find a way to print out a vector that contains the sum of the X1 and X2 columns in testdata?\nWhat is the total sum of all the numbers in the X1 and X2 columns of testdata?\n\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n# 1\nncol(testdata)\n\n# 2 \ntestdata$X1 + testdata$X2\n\n# 3\nsum(testdata$X1 + testdata$X2)\n\n\n\n\n\n\n\n\n\nWe introduce the main package for the plotting engine that we will use in this course; ggplot2, and its basic syntax.\n\n# A simple scatterplot\nplot(testdata$X1, testdata$X2)\n\n# Making adjustments to the plot\nplot(testdata$X1, testdata$X2,\n     pch = 20,\n     bty = \"l\",\n     xlab = \"X1\",\n     ylab = \"X2\")\n\n# Load the ggplot2-package\nlibrary(ggplot2)\n\n# Here is the code for creating a simple scatterplot of the X1 and X2 columns in\n# our data set:\nggplot(testdata, aes(x = X1, y = X2)) + geom_point()\n\n# First make the plot, then save it to a file\nggplot(testdata, aes(x = X1, y = X2)) + geom_point()\nggsave(\"testplot.pdf\")\n\n# A more flexible way to do it is to save the plot in a variable, and then\n# supply the name of the plot to the ggsave-finction:\np <- ggplot(testdata, aes(x = X1, y = X2)) + geom_point()\nggsave(\"testplot.pdf\", p)\n\n# That way, we can save the plot p at any time, we do not have to do it directly\n# after the plotting commands.\n\nExercise: Can you figure out how to make the dots in the plot bigger and blue?\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\nggplot(testdata, aes(x = X1, y = X2)) + geom_point(colour = \"blue\", size = 5)\n\n\n\n\n\n\n\n\n\nIn this video we stop writing code directly in the console, and rather write our code in a script file, which is simply a pure text file containing commands. There are two important new concepts that we have to pay attention to when writing scripts:\n\nThe comment character #: Evertything after this character in an R-script is ignored when executing the script. We can use the comment character to add small comments to our code, briefly explaining what is going on. This is a great help for other people trying to understand what you have done, in particular, and perhaps most importantly: the future you returning to a project. The comment character # is the same as in Python.\nThe keybinding Ctrl - Enter (Cmd - Enter on a Mac) executes the line where your cursor is located in the script. You can also select several lines and execute all of them using this shortcut.\n\n\n# Introduction to R\n# -------------------\n\n# Load packages \nlibrary(readxl)\nlibrary(ggplot2)\n\n# Read our data set\ntestdata <- read_xls(\"testdata.xls\")\n\n# Make a scatterplot of the X1 and X2-variables\nplot <- ggplot(testdata, aes(x = X1, y = X2)) + \n    geom_point() + \n    ggtitle(\"Scatterplot of testdata\") +\n    theme_classic()\nggsave(\"testplot.pdf\", plot)\n\nExercise: Make sure to save your script as an .R-file in the folder that we created for this session. Close RStudio. Then navigate to the folder and double click on the script file. Hopefully RStudio opens (if not, right click, select “Open in” and then Rstudio, confirm if prompted to set RStudio as default program for opening .R-files).\nFind out what your working directory is now. What just happened? How is this useful?\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\nOpening RStudio by double clicking on the script file automatically sets the working directory to the location of the script file. Very useful when returning to a project.\n\n\n\n\n\n\n\n\nWe introduce the pipe operator %>%, which allows us to apply a sequence of functions in a practical way that allows us to read the code from left to right, just as we read normal text.\nIf you installed the dplyr-package in the “Packages”-section, then you have already installed the magrittr-package that includes the pipe. The shortcut for the pipe in RStudio is Ctrl - Shift - M on Windows, and Cmd - Shift - M on a Mac.\nWe will use this technique extensively throughout the course!\n\n# For this lesson, you need to have magrittr installed. Run the line \n# below if you don't have it already: \n# install.packages(\"magrittr\")\n\n# Create some data:\nx <- (-500):500\n\n# Want to calculate mean of sqrt of abs values of x...\n# one way: via temporary variables: \nabs.x <- abs(x)\nsqrt.abs.x <- sqrt(abs.x)\nalt.1 <- mean(sqrt.abs.x)\n\n# ...or collapse them all with nested functions: \nalt.2 <- mean(sqrt(abs(x)))\n\nlibrary(magrittr)\n# With Magrittr: \n# x %>% f() is equivalent to  f(x)\n# Why would we want to do this: \n#  - code becomes more easy to read\n#  - easier to develop code, particularly when dealing with data sets\n\n#  Example 1\nsqrt(2)\n2 %>% sqrt\n\n#  Example 2\nmean(c(1,2,NA), na.rm=T)\nc(1,2,NA) %>% mean(na.rm=T)\n\n# Example 3\n(-2)^2\n-2 %>% .^2\n\n# Example 4\natan2(1,2)\n2 %>% atan2(1,.)\n\nExercise:\nUse magrittr to calculate the equivalent of alt.1 and alt.2\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n\n\nalt.3 <- \n  x %>% \n  abs %>% \n  sqrt %>% \n  mean\n\nalt.1\nalt.2\nalt.3"
  },
  {
    "objectID": "02-data-wrangling.html",
    "href": "02-data-wrangling.html",
    "title": "BAN400 - R Programming for Data Science",
    "section": "",
    "text": "In this section we will learn how to handle data in a very efficient way. We will learn to\n\nfilter a data set based on variable values,\nselect variables,\ncreate new variables,\ngroup data based on variables,\ndummarise the data, and\njoin different data sets.\n\nWe will obviously use R to solve these problems, but we do have the choice between different coding styles to do it. One way is to only use functions that already ship with R, or we can use functions from additional packages to solve the same problems. We choose the latter, and not only that: We will thoughout this course use a specific set of packages, an ecosystem if you wish (or even a philosophy of data work), called the tidyverse.\nThe tidyverse (tidyverse.org) is a set of R packages that work very well together, follows a consistent logic, and that enables us to write extremely clean code. We have already touched upon the difference between data wrangling using base R and the tidyverse in Chapter 1.9.\nSee the video below for some more details regarding the tidyverse. Some formulations in the video gives the impression that this material should be consumed on a specific day, but that are just some residue from a time when this part of the course was given intensively. You can find the cheat sheet here. See also this webpage for further information about one of the most central packages in tidyverse, dplyr.\n\n\n\n\n\n\nFirst, we warm up with a first few functions from dplyr. Note how the syntax is similar to how we use the magrittr-pipe %>%. You can download the data set here: data-geilo.xlsx.\nExercise: Report the top of the dataset, sorted by\n\ncocoa (increasing)\nswix (decreasing)\norange (decreasing)\n\nYou should obtain a result equal to the data frame below. Note we only show the first six entries of the result.\n\n\n# A tibble: 6 x 5\n  trans customer orange cocoa  swix\n  <dbl>    <dbl>  <dbl> <dbl> <dbl>\n1    21       42      5     0     7\n2    19        7      4     0     2\n3    12       10      3     0     0\n4    20       NA      1     1     2\n5     5       NA      3     1     1\n6     9       NA      2     1     1\n\n\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\nsales %>%\n  arrange(cocoa, desc(swix), desc(orange)) %>%\n  head\n\n# Alternatively: \n sales %>%\n   arrange(cocoa, -swix, -orange) %>%\n   head\n \n# Note however that (-) requires num. vectors. desc can take e.g. factors as well.)\n\n\n\n\n\n\n\n\n\n\n# Selecting some variables: \nhead(sales[,c(\"swix\", \"cocoa\")])\n\nsales %>%\n  select(cocoa, swix) %>%\n  head\n\n# create new variables: \nsales %>%\n  mutate(items = cocoa+swix+orange) %>%\n  head\n\nsales %>%\n  transmute(\n    items = cocoa+swix+orange,\n    trans = trans) %>%\n  head\n\n# Summarise data: \nsales %>%\n  summarise(sum_cocoa = sum(cocoa))\n\n# Assignment 1: how many items were sold in total?\n# Assignment 2: What was the max and min number of items bought by\n# the people that also bought cocoa?\n\nExercise:\n\nHow many items were sold in total?\nWhat is the min. and max. number of items purchased by customers that also bought at least one cocoa?\n\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n\n\n# Exercise 1: \n\nsales %>%\n  transmute(items = cocoa + swix + orange) %>%\n  summarise(sum_items = sum(items))\n\n# Exercise 2: \nsales %>%\n  filter(cocoa>0) %>%\n  transmute(\n    items = cocoa + swix + orange) %>%\n  summarise(\n    max_items = max(items),\n    min_items = min(items)\n  )\n\n\n\n\n\n\n\n\n\n\n# Compare the output from this command: \nsales\n\n# ..to this one: \nsales %>% group_by(customer)\n\n# Note how we in the second command have added some meta-information on groups\n# to the data frame. Groups change the results we get when applying\n# functions to the data frame. See below: \n\nsales %>%\n  summarise(\n    sum.orange = sum(orange),\n    no.trans = n()) \n\nsales %>%\n  group_by(customer) %>%\n  summarise(\n    sum.orange = sum(orange),\n    no.trans = n()) \n\n# When we apply \"summarise\" to a data frame we are reducing it \n# to the summary statistics that we list in the call to the function. \n# In the command above, this is a sum and a count. There are many\n# such functions we can use - just keep in mind that the function\n# should return one item per group (or just one item if you don't\n# have groups). \n# \n# Make sure you are aware of the difference between mutate and \n# summarise: mutate *adds* a variable to the data frame, \n# summarise aggregates it. \n\nExercise: How many cocoas were bought in total by customers who also bought more than two oranges? (Hint: How does mutate work on a grouped data frame?)\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n\n\nsales %>%\n  group_by(customer) %>%\n  mutate(sum.orange = sum(orange)) %>%\n  filter(sum.orange > 2) %>%\n  summarise(sum.cocoa = sum(cocoa))\n\n\n\n\n\n\n\n\n\nFinally, we will join data frames. See the data wrangling cheat sheet, under the header “Combine data sets”.\n\n# Read in both sheets\nsales <- read_excel(\"../datasett/Geilo.xlsx\", sheet=\"Sales\")\ncustomers <- read_excel(\"../datasett/Geilo.xlsx\", sheet=\"Customers\")\n\n# See that sales stores transactions, as well as a link to a \n# customer number: \nhead(sales)\n\n# In the \"customers\"-file we find info on each customer: \nhead(customers)\n\nExercise: Use the dplyr join verbs to create the following four different results:\n\nA dataframe with transactions and customer info filled in\nA dataframe with transactions for all registered customers\nA dataframe with transactions for customers that are not registered\nA dataframe that combines all the information in both data sets\n\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n\n\nsales %>%\n  left_join(customers, by=\"customer\") %>%\n  group_by(hotel) %>% \n  summarise(\n    sum_orange = sum(orange))\n\n  arrange(customer) %>%\n  head\n\n# 1: \nsales %>%\n  left_join(customers, by=\"customer\") %>%\n  arrange(customer) %>%\n  head\n\n# 2: \nsales %>%\n  semi_join(customers, by=\"customer\") %>%\n  arrange(customer) %>%\n  head\n\n# 3: (why does this give different res. than is.na()?)\nsales %>%\n  anti_join(customers, by=\"customer\") %>%\n  arrange(customer) %>%\n  head\n\n# 4:\nfull <- \n  sales %>%\n  full_join(customers, by = \"customer\")\n\n\n\n\n\n\n\nA word of caution on tidyverse: dplyr is somewhat contested among R-users. Some claim it is very easy to learn (although I’m not aware of any studies). Critics argue that it is slow compared to data.table. data.tablecan (sometimes) beat Python/Pandas in terms of spee not, but dplyr can not do that. Note also that the tidyverse ecosystem in general is continually being updated. This means that if you try to run the commands from this course on a fresh install of R and Tidyverse in a few years, it might not work unless you update the syntax.\nThink about your usage of programming: If it is occasional scripting, ad-hoc reports etc, then speed is often not important, and occasionally changing syntax might not be an issue.\nHowever, in my experience the tidyverse is significantly “faster” than alternatives for important use cases - which involve many exploratory analyses, data visualizations, and trying out many different ways of modelling a problem (i.e. usually what constrains your time may be how fast you can express what you want - not how long you need to wait for results).\nLet’s wrap up this chapter with a final exercise:\nExercise: Create a summary statistics with the following properties:\n\nCustomer on rows, with all customers as well as non-registered customers (non-registered can be in a single row)\nIn addition to customer numbers, four columns:\n\nNumber of transactions in total\nTotal sales of each type of item\n\n\n\n\n\n\n\n\nExpand for solution\n\n\n\n\n\n\n\n\n# Why doesn't this work!?\n#(check e.g. customer nr 2!):\nfull %>% \n  arrange(customer) %>%\n  mutate(\n    customer=replace_na(customer, \"Unregistered\")\n  ) %>%\n  group_by(customer) %>%\n  summarise(count         = n(),\n            sale.orange   = sum(orange, na.rm=T),\n            sale.cocoa    = sum(cocoa   , na.rm=T),\n            sale.swix     = sum(swix    , na.rm=T))\n\n\n# A better way: \nsumstats <-\n  full %>%\n  arrange(customer) %>%\n  mutate(customer = replace_na(customer, \"Unregistered\")) %>%\n  group_by(customer) %>%\n  summarise(\n    count         = sum(!is.na(trans)),\n    sale.orange   = sum(orange, na.rm = T),\n    sale.cocoa    = sum(cocoa   , na.rm = T),\n    sale.swix     = sum(swix    , na.rm = T)\n  )"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Håkon Otneim: hakon.otneim@nhh.no\nOle-Petter Moe Hansen: ole-petter.hansen@nhh.no"
  },
  {
    "objectID": "assignment-01.html",
    "href": "assignment-01.html",
    "title": "BAN400 - R Programming for Data Science",
    "section": "",
    "text": "We will look at the monthly returns on the NASDAQ composite stock index from August 2013 to June 2018, as well as the returns on 16 individual stocks listed on NASDAQ. The data is contained in the file data-nasdaq-returns.xls, and has been collected from the Yahoo Finance website.\nPut the data in an appropriate folder on your computer. Perform the following tasks:\n\nRead the data into R and take a first look at the data set. The main index is in the NASDAQ-column.\n\n\n\n\n\n\n\nClick here to see how the top of the data set should look like after you have loaded it into R.\n\n\n\n\n\n\n\n# A tibble: 59 x 11\n   Date     NASDAQ    ADBE     AMZN     AAPL     BBBY     CSCO    CMCSA     COST\n   <chr>     <dbl>   <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n 1 2013-0~ -0.0101 -0.0329 -0.0696   0.0739  -3.64e-2 -0.0933  -0.0686  -0.0484 \n 2 2013-0~  0.0494  0.127   0.107   -0.0217   4.79e-2  0.00513  0.0695   0.0291 \n 3 2013-1~  0.0386  0.0430  0.152    0.0920  -5.17e-4 -0.0378   0.0535   0.0243 \n 4 2013-1~  0.0351  0.0461  0.0781   0.0619   9.14e-3 -0.0598   0.0466   0.0611 \n 5 2013-1~  0.0283  0.0532  0.0130   0.00886  2.87e-2  0.0540   0.0412  -0.0525 \n 6 2014-0~ -0.0176 -0.0116 -0.106   -0.114   -2.29e-1 -0.0235   0.0466  -0.0576 \n 7 2014-0~  0.0486  0.148   0.00946  0.0500   6.03e-2 -0.00503 -0.0520   0.0388 \n 8 2014-0~ -0.0257 -0.0430 -0.0737   0.0198   1.43e-2  0.0280  -0.0324  -0.0448 \n 9 2014-0~ -0.0203 -0.0636 -0.101    0.0948  -1.02e-1  0.0303   0.0338   0.0352 \n10 2014-0~  0.0306  0.0452  0.0273   0.0702  -2.08e-2  0.0633   0.00846  0.00293\n# ... with 49 more rows, and 2 more variables: DLTR <dbl>, EXPE <dbl>\n\n\n\n\n\n\nMake a new data frame containing only the date column and returns on the main index as well as one of the individual stocks of your choosing. Name the new data frame appropriately.\n\n\n\n\n\n\n\nClick here to see how the top of the new data set should look like.\n\n\n\n\n\nFor example, after picking ADBE as the stock:\n\n\n# A tibble: 59 x 3\n   Date        NASDAQ    ADBE\n   <chr>        <dbl>   <dbl>\n 1 2013-08-01 -0.0101 -0.0329\n 2 2013-09-01  0.0494  0.127 \n 3 2013-10-01  0.0386  0.0430\n 4 2013-11-01  0.0351  0.0461\n 5 2013-12-01  0.0283  0.0532\n 6 2014-01-01 -0.0176 -0.0116\n 7 2014-02-01  0.0486  0.148 \n 8 2014-03-01 -0.0257 -0.0430\n 9 2014-04-01 -0.0203 -0.0636\n10 2014-05-01  0.0306  0.0452\n# ... with 49 more rows\n\n\n\n\n\n\nMake a scatterplot of the two variables in your newly created data frame.\n\n\n\n\n\n\n\nClick here to see the plot should look like.\n\n\n\n\n\nStill, using ADBE, will of course look a bit different if you have chosen a different stock:\n\n\n\n\n\n\n\n\n\nThe function sign(x) returns the sign of x, that is, it returns -1 if x is negative and 1 if x is positive. Make two new columns, named sign_NASDAQ and a corresponding name for the stock that you have chosen to include, that contains the sign of the return, indicating whether the index or stock went up or down that day.\n\n\n\n\n\n\n\nClick here to see how the top of the new data set should look like.\n\n\n\n\n\n\n\n# A tibble: 59 x 5\n   Date        NASDAQ    ADBE NASDAQ_sign ADBE_sign\n   <chr>        <dbl>   <dbl>       <dbl>     <dbl>\n 1 2013-08-01 -0.0101 -0.0329          -1        -1\n 2 2013-09-01  0.0494  0.127            1         1\n 3 2013-10-01  0.0386  0.0430           1         1\n 4 2013-11-01  0.0351  0.0461           1         1\n 5 2013-12-01  0.0283  0.0532           1         1\n 6 2014-01-01 -0.0176 -0.0116          -1        -1\n 7 2014-02-01  0.0486  0.148            1         1\n 8 2014-03-01 -0.0257 -0.0430          -1        -1\n 9 2014-04-01 -0.0203 -0.0636          -1        -1\n10 2014-05-01  0.0306  0.0452           1         1\n# ... with 49 more rows\n\n\n\n\n\n\nMake another column consisting of the sum of the two sign columns divided by two. The resulting value will then be -1 if both the index and the stock went down that day, 0 if they went in separate directions, and 1 if both went up.\n\n\n\n\n\n\n\nClick here to see how the top of the new data set should look like.\n\n\n\n\n\n\n\n# A tibble: 59 x 6\n   Date        NASDAQ    ADBE NASDAQ_sign ADBE_sign   sum\n   <chr>        <dbl>   <dbl>       <dbl>     <dbl> <dbl>\n 1 2013-08-01 -0.0101 -0.0329          -1        -1    -1\n 2 2013-09-01  0.0494  0.127            1         1     1\n 3 2013-10-01  0.0386  0.0430           1         1     1\n 4 2013-11-01  0.0351  0.0461           1         1     1\n 5 2013-12-01  0.0283  0.0532           1         1     1\n 6 2014-01-01 -0.0176 -0.0116          -1        -1    -1\n 7 2014-02-01  0.0486  0.148            1         1     1\n 8 2014-03-01 -0.0257 -0.0430          -1        -1    -1\n 9 2014-04-01 -0.0203 -0.0636          -1        -1    -1\n10 2014-05-01  0.0306  0.0452           1         1     1\n# ... with 49 more rows\n\n\n\n\n\n\nWe would like to count the number of days for which the new sum-column is either -1, 0, or 1. Do that by applying the function table() to the sum-column. (Recall that we can pick out individual columns using the dollar-sign).\n\n\n\n\n\n\n\nClick here to see how the output should look like.\n\n\n\n\n\nFor the ADBE-stock:\n\n\n\n-1  0  1 \n15 10 34 \n\n\n\n\n\n\nIn the tasks above you may (or may not) have created several intermediate data frames under different names for each problem, or perhaps you have overwritten the data frame for each new task. Let us rather complete task 1, 2, 4 and 5 in one single operation, where you just append each task to the previous using the pipe-operator. That way you only need to come up with one name for the data set.\n\n\n\n\n\n\n\nClick here to see to see a hint if you need to.\n\n\n\n\n\nThe code may look something like this, replace the dots:\n\nstock_data <-\n  read_excel(...) %>%       \n  select(...) %>%                  \n  mutate(...) %>%          \n  mutate(...) %>%              \n  mutate(...)       \n\n\n\n\n\n\n\nThe .csv-file (comma separated values) is a common format for storing data in a plain text file. The file data-missile.csv contains data on North Korean missile launches from 1984 until 2017. Put the file in folder on your computer and inspect the contents by opening it in a text editor such as Notepad or Textedit.\nR ships with a function read.csv() that we can use to read csv-files in the same way as we use read_excel() to read excel-files. We will, however, use a function from the readr-package called read_csv() for this purpose that does almost the same thing as the default read.csv()-function. There are some subtle differences between these two functions that are not very important, but read_csv() works a little bit better together with many other functions and packages that we will use later.\nLoad readr using the library() function. If you get an error message telling you that there is no package called 'readr', then you need to install it first using the install.packages()-function.\nLoad the data into into R using the following command:\n\nmissile <- read_csv(\"data-missile.csv\")\n\nLook at the data. The variable «apogee» is the highest altitude reached by the missile in km. Calculate the following statistics for this variable:\n\nThe mean.\nThe median.\nThe standard deviation.\n\n\n\n\n\n\n\nMaybe you get some unexpected results here. You need to troubleshoot the problem in order to solve the issue. Click here if you need some hints on what to try.\n\n\n\n\n\nThe problem is that you get NA-values right? Why is this? Look at the data, and you will see that many values are missing, and they should be ignored when calculating the mean, median and standard deviation. Look at the help files for the functions in question (e.g. ?mean) to see if there is something you can to to fix the issue."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BAN400 - R Programming for Data Science",
    "section": "",
    "text": "This is the companion website for the course BAN400 - R Programming for Data Science, given at The Norwegian School of Economics (NHH). The purpose of this website is to provide study material such as lecture videos, exercises and assignments for students taking the course.\nBAN400 has previously consisted of two separate modules; one intensive one-week introduction to R that could be taken separately as a 2.5 ECTS course as BAN420, as well as the main course itself (pun intended), which, together with BAN420, completed the 7.5 ECTS unit BAN400.\nFrom the fall semester of 2023, we do no longer offer the intensive option. BAN400 is now offered as one regular course. We will, however, still make an explicit transition from Part 1, where we introduce basic programming, to Part 2 where we will learn a number of useful techniques that are particularly useful when working with data.\nAll announcements and course administration such as homework delivery and feedback will be carried out through the course page at Canvas, which is the learning management system used by NHH. You will need to sign up to the course in order to gain access to the Canvas page."
  }
]